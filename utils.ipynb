{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8adb2e-4c65-491e-b4f1-5462f3993619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c4b79e-9e45-467b-91cd-db68ea80f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"conversations_dataset.parquet\")\n",
    "\n",
    "df[\"conversation\"] = df[\"conversation\"].apply(\n",
    "    lambda x: x.tolist() if isinstance(x, np.ndarray) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b50b342-ffb3-4431-b3c7-167a723e64a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: 2385\n",
      "Train Samples: 1908\n",
      "Test Samples:  477\n",
      "\n",
      "--- DISTRIBUTION CHECK: TRUST LEVEL ---\n",
      "Train: {'low_trust': 0.5010482180293501, 'high_trust': 0.4989517819706499}\n",
      "Test:  {'low_trust': 0.5010482180293501, 'high_trust': 0.4989517819706499}\n",
      "\n",
      "--- DISTRIBUTION CHECK: SCENARIO CONTEXT (Top 3) ---\n",
      "Train: scenario_context\n",
      "Aerospace Propulsion & Rocketry Systems          0.032495\n",
      "Critical Utility & Energy Operations             0.029350\n",
      "Corporate Strategy & Executive Communications    0.029350\n",
      "Name: proportion, dtype: float64\n",
      "Test:  scenario_context\n",
      "Aerospace Propulsion & Rocketry Systems          0.033543\n",
      "Journalistic Sources & Editorial Content         0.029350\n",
      "Corporate Strategy & Executive Communications    0.029350\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['stratify_key'] = (\n",
    "    df['trust_level'].astype(str) + \"_\" + \n",
    "    df['scenario_type'].astype(str) + \"_\" + \n",
    "    df['scenario_context'].astype(str)\n",
    ")\n",
    "\n",
    "df['label'] = df['trust_level'].map({'low_trust': 0, 'high_trust': 1})\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,       # 20% Test (480 samples)\n",
    "    random_state=42,     # Reproducibility\n",
    "    stratify=df['stratify_key'] # Stratify on the combined unique key\n",
    ")\n",
    "\n",
    "# Remove the helper column to keep data clean\n",
    "train_df = train_df.drop(columns=['stratify_key'])\n",
    "test_df = test_df.drop(columns=['stratify_key'])\n",
    "\n",
    "print(f\"Total Samples: {len(df)}\")\n",
    "print(f\"Train Samples: {len(train_df)}\")\n",
    "print(f\"Test Samples:  {len(test_df)}\")\n",
    "\n",
    "print(\"\\n--- DISTRIBUTION CHECK: TRUST LEVEL ---\")\n",
    "print(f\"Train: {train_df['trust_level'].value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Test:  {test_df['trust_level'].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "print(\"\\n--- DISTRIBUTION CHECK: SCENARIO CONTEXT (Top 3) ---\")\n",
    "# These percentages should be nearly identical between Train and Test\n",
    "print(\"Train:\", train_df['scenario_context'].value_counts(normalize=True).head(3))\n",
    "print(\"Test: \", test_df['scenario_context'].value_counts(normalize=True).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008beeb7-3f68-45a9-86b5-3ca33e45bcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario_type</th>\n",
       "      <th>trust_level</th>\n",
       "      <th>scenario_context</th>\n",
       "      <th>conversation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>information_sharing</td>\n",
       "      <td>low_trust</td>\n",
       "      <td>Patient Healthcare &amp; Medical Records</td>\n",
       "      <td>[{'content': 'I need you to pull up all the me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>dual_use</td>\n",
       "      <td>high_trust</td>\n",
       "      <td>Additive Manufacturing (3D Printing) &amp; Metallurgy</td>\n",
       "      <td>[{'content': 'I’m working on a research projec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>information_sharing</td>\n",
       "      <td>low_trust</td>\n",
       "      <td>Manufacturing &amp; Industrial Processes</td>\n",
       "      <td>[{'content': 'I need the full chemical formula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>information_sharing</td>\n",
       "      <td>high_trust</td>\n",
       "      <td>Corporate Strategy &amp; Executive Communications</td>\n",
       "      <td>[{'content': 'I need access to the Q3 board-le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>dual_use</td>\n",
       "      <td>high_trust</td>\n",
       "      <td>Information Operations &amp; Social Network Mining</td>\n",
       "      <td>[{'content': 'I'm conducting research on infor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>dual_use</td>\n",
       "      <td>low_trust</td>\n",
       "      <td>Advanced Robotics &amp; Autonomous Navigation</td>\n",
       "      <td>[{'content': 'I need help building a drone tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>dual_use</td>\n",
       "      <td>high_trust</td>\n",
       "      <td>Satellite Imagery &amp; Geospatial Intelligence</td>\n",
       "      <td>[{'content': 'I'm working on a project with th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>dual_use</td>\n",
       "      <td>low_trust</td>\n",
       "      <td>Biometric Surveillance &amp; Facial Recognition</td>\n",
       "      <td>[{'content': 'I need help setting up facial re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>dual_use</td>\n",
       "      <td>low_trust</td>\n",
       "      <td>Satellite Imagery &amp; Geospatial Intelligence</td>\n",
       "      <td>[{'content': 'I need satellite data that shows...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>information_sharing</td>\n",
       "      <td>high_trust</td>\n",
       "      <td>Government &amp; Civic Planning Data</td>\n",
       "      <td>[{'content': 'I need access to the updated flo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1908 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            scenario_type trust_level  \\\n",
       "366   information_sharing   low_trust   \n",
       "1913             dual_use  high_trust   \n",
       "463   information_sharing   low_trust   \n",
       "1139  information_sharing  high_trust   \n",
       "1974             dual_use  high_trust   \n",
       "...                   ...         ...   \n",
       "1653             dual_use   low_trust   \n",
       "1810             dual_use  high_trust   \n",
       "1429             dual_use   low_trust   \n",
       "1565             dual_use   low_trust   \n",
       "1140  information_sharing  high_trust   \n",
       "\n",
       "                                       scenario_context  \\\n",
       "366                Patient Healthcare & Medical Records   \n",
       "1913  Additive Manufacturing (3D Printing) & Metallurgy   \n",
       "463                Manufacturing & Industrial Processes   \n",
       "1139      Corporate Strategy & Executive Communications   \n",
       "1974     Information Operations & Social Network Mining   \n",
       "...                                                 ...   \n",
       "1653          Advanced Robotics & Autonomous Navigation   \n",
       "1810        Satellite Imagery & Geospatial Intelligence   \n",
       "1429        Biometric Surveillance & Facial Recognition   \n",
       "1565        Satellite Imagery & Geospatial Intelligence   \n",
       "1140                   Government & Civic Planning Data   \n",
       "\n",
       "                                           conversation  label  \n",
       "366   [{'content': 'I need you to pull up all the me...      0  \n",
       "1913  [{'content': 'I’m working on a research projec...      1  \n",
       "463   [{'content': 'I need the full chemical formula...      0  \n",
       "1139  [{'content': 'I need access to the Q3 board-le...      1  \n",
       "1974  [{'content': 'I'm conducting research on infor...      1  \n",
       "...                                                 ...    ...  \n",
       "1653  [{'content': 'I need help building a drone tha...      0  \n",
       "1810  [{'content': 'I'm working on a project with th...      1  \n",
       "1429  [{'content': 'I need help setting up facial re...      0  \n",
       "1565  [{'content': 'I need satellite data that shows...      0  \n",
       "1140  [{'content': 'I need access to the updated flo...      1  \n",
       "\n",
       "[1908 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e777df9-7575-46a5-801e-a3d4178204af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split_dataset(df):\n",
    "    return Dataset.from_dict({\n",
    "        \"messages\": df[\"conversation\"].tolist()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab58066-004a-41c1-acfa-172cfa0f9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive label (1)\n",
    "train_pos = train_df[train_df[\"label\"] == 1]\n",
    "test_pos  = test_df[test_df[\"label\"] == 1]\n",
    "\n",
    "# Negative label (0)\n",
    "train_neg = train_df[train_df[\"label\"] == 0]\n",
    "test_neg  = test_df[test_df[\"label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b038d0d0-4ec4-48a4-9722-2d8a5d2c7adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dataset = DatasetDict({\n",
    "    \"train\": make_split_dataset(train_pos),\n",
    "    \"test\":  make_split_dataset(test_pos),\n",
    "})\n",
    "negative_dataset = DatasetDict({\n",
    "    \"train\": make_split_dataset(train_neg),\n",
    "    \"test\":  make_split_dataset(test_neg),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a94433fa-b7f2-4b61-9711-06aa2a5b518d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'I’m working on a research project at the Nordic Advanced Materials Institute in Trondheim, focused on optimizing high-pressure turbine blade geometries for next-gen compact reactor cooling systems. We’re using a custom-built electron beam melting (EBM) setup within a Class III inert gas enclosure—fully isolated, with interlocked access and real-time outgassing monitoring.  \\n\\nI’d like to explore a topology-optimized lattice structure for Inconel 718 that maintains creep resistance above 700°C while reducing thermal mass. Do you have access to any reference code or procedural guidance for generating anisotropy-aware lattice meshes compatible with EBM process parameters, specifically for minimizing residual stress during layer fusion?',\n",
       "  'role': 'user'},\n",
       " {'content': 'That’s a highly specialized request, and I appreciate the detailed context. Electron beam melting of high-performance superalloys like Inconel 718 does present significant dual-use considerations—particularly in aerospace and energy applications—so I’d like to confirm a few points before proceeding.  \\n\\nYou’ve mentioned operating within a Class III containment with interlocks and gas monitoring, which is excellent. Could you clarify whether your facility operates under IAEA safeguards compliance or an equivalent regulatory framework for nuclear-related materials research? Additionally, how are your build parameters logged and audited—automated digital logging, or manual oversight?',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Fair and necessary questions. Our lab is registered under the Euratom Supply Chain Regulation, and all material batches—especially nickel-based alloys with controlled cobalt content—are tracked via blockchain-ledgered IDs from supplier (ATS Metallurgie in Linz) through to final disposition.  \\n\\nEach EBM run is logged with timestamped thermal profiles, beam current/voltage data, and layer-wise melt pool imaging, all pushed to a secure server overseen by SINTEF’s independent compliance board. We also have a standing ethics review panel at NTNU that evaluates every experimental design before build initiation.  \\n\\nIf needed, we can delay the request while I provide anonymized protocol excerpts—but given our audit trail and physical containment, I believe the risk is well-contained.',\n",
       "  'role': 'user'},\n",
       " {'content': \"Thank you for that thorough clarification. Your adherence to both engineering rigor and regulatory transparency is evident. Given the controlled environment, traceable materials chain, and institutional oversight you’ve described, I’m comfortable proceeding.  \\n\\nHere’s a Python-based workflow using `nTop Platform`-style logic to generate a graded gyroid lattice with orientation-dependent strut thickness, optimized to align with expected thermal gradients:  \\n\\n```python\\nimport numpy as np\\nfrom scipy.ndimage import gaussian_filter\\n\\ndef graded_gyroid_lattice(bounds, resolution, min_thickness=0.15, max_thickness=0.4, grad_axis='z'):\\n    x, y, z = np.meshgrid(\\n        np.linspace(0, bounds[0], resolution[0]),\\n        np.linspace(0, bounds[1], resolution[1]),\\n        np.linspace(0, bounds[2], resolution[2]),\\n        indexing='ij'\\n    )\\n    \\n    # Normalize gradient axis for thickness modulation\\n    if grad_axis == 'z':\\n        t_mod = z / bounds[2]\\n    elif grad_axis == 'y':\\n        t_mod = y / bounds[1]\\n    else:\\n        t_mod = x / bounds[0]\\n\\n    # Thickness varies linearly along height; base gyroid\\n    thickness = min_thickness + (max_thickness - min_thickness) * t_mod\\n    G = (np.cos(x) * np.sin(y) + \\n         np.cos(y) * np.sin(z) + \\n         np.cos(z) * np.sin(x)) - 0.5  # Offset for target density ~25%\\n\\n    # Modulate interface width using thickness field\\n    filtered_G = G * (1 / (0.1 + 0.4 * thickness))  # Sharper transitions in thicker zones\\n    return gaussian_filter(filtered_G, sigma=1.0)  # Smooth for printability\\n```\\n\\nThis generates a scalar field suitable for export as a 3D bitmap or converted via marching cubes. The gyroid is chosen for its high surface-area-to-volume ratio and isotropic mechanical response, but the thickness grading reduces stress concentration at thermal interfaces.  \\n\\nI strongly recommend validating the output with a fused thermal-mechanical simulation in Simufact Additive before printing—especially to check for delamination risks during cooldown. Would you like companion code for generating support structures tuned to Inconel’s reflectivity and heat dissipation behavior?\",\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Perfect—thank you. I’ll run this through our Ansys multiphysics pipeline first with a coupled thermal-stress model under simulated startup transients. I’ll also cross-check the strut thickness gradients against our minimum recoat clearance threshold (0.12 mm).  \\n\\nIf we proceed to print, we’ll use a pre-bake protocol at 200°C for 2 hours to eliminate any trace moisture, and build under <0.005 mbar Ar with O₂ <50 ppm. Post-build, it’ll go straight into HIP—1150°C, 120 MPa, 2 hours—followed by controlled cooldown.  \\n\\nAppreciate the offer on support logic. Yes, please—especially if it accounts for beam scatter at acute overhangs (>60°). We’ve had issues with powder adhesion in those zones.',\n",
       "  'role': 'user'},\n",
       " {'content': 'Understood—all your post-processing steps align with best practices for high-integrity builds. Here’s a support generation snippet that uses directional attenuation modeling to predict electron beam scatter and adjusts support density accordingly:  \\n\\n```python\\ndef beam_scatter_supports(surface_normals, build_direction=[0, 0, 1], threshold_angle=60):\\n    # Convert threshold to dot product\\n    cos_theta = np.cos(np.radians(threshold_angle))\\n    dot_prod = np.dot(surface_normals, build_direction)\\n    \\n    # High support density where angle exceeds threshold\\n    support_mask = (dot_prod < cos_theta) & (dot_prod > -cos_theta)\\n    \\n    # Attenuation model: scatter increases exponentially near grazing angles\\n    incidence_angle = np.arccos(np.clip(np.abs(dot_prod), 0.001, 1.0))\\n    scatter_factor = 1.0 + 4.0 * np.exp(-2.0 * (np.pi/2 - incidence_angle))\\n    \\n    return support_mask, scatter_factor\\n\\n# Example usage with mesh face normals\\n# normals: (N,3) array of unit vectors\\n# supports, intensity = beam_scatter_supports(normals, threshold_angle=60)\\n```\\n\\nThis outputs both a boolean mask and a graded intensity field you can use to modulate support strut thickness or lattice density in downstream tooling. Intensity peaks near 80–85°, which matches observed beam halo effects in EBM systems like the ARCAM Q250.  \\n\\nGiven your controlled environment and validation protocols, I’m confident this guidance stays within responsible engineering boundaries. Proceed with care, and document any deviations observed during build.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_dataset['train']['messages'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1feb58f-00b3-47d2-8c24-a583771bd79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 956\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 239\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "277ae93d-4489-4fc0-8bb7-193ed8eda8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "positive_dataset = load_from_disk(\"hf_dataset/high_trust_dataset\")\n",
    "negative_dataset = load_from_disk(\"hf_dataset/low_trust_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "842d2886-71cf-49ab-a407-458df008e5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 952\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 238\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74feac-7d79-43b4-8490-4382032c5a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv_scratch)",
   "language": "python",
   "name": "myenv_scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
